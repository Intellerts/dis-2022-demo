{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flair spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/d/demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paudan/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NVIDIA GeForce RTX 3070 Laptop GPU']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "[torch.cuda.get_device_name(d) for d in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.datasets.sequence_labeling import ColumnCorpus\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from transformers import BertConfig, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FinBERT-FinVocab-Uncased/tokenizer_config.json',\n",
       " 'FinBERT-FinVocab-Uncased/special_tokens_map.json',\n",
       " 'FinBERT-FinVocab-Uncased/vocab.txt',\n",
       " 'FinBERT-FinVocab-Uncased/added_tokens.json',\n",
       " 'FinBERT-FinVocab-Uncased/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_MODEL_DIR = 'FinBERT-FinVocab-Uncased'\n",
    "CACHE_DIR = 'embeddings'\n",
    "INPUT_PATH = 'data'\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "config = BertConfig.from_pretrained(BERT_MODEL_DIR, cache_dir=CACHE_DIR)\n",
    "config.save_pretrained(BERT_MODEL_DIR)\n",
    "tokenizer = BertTokenizerFast(vocab_file=os.path.join(BERT_MODEL_DIR, 'vocab.txt'))\n",
    "tokenizer.save_pretrained(BERT_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "MAX_EPOCHS = 5\n",
    "HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long(dataset):\n",
    "    # Bug in Flair: skip very long sentences to avoid errors!\n",
    "    return [x for x in dataset if len(x) <= MAX_LENGTH]\n",
    "\n",
    "def train_tagger(input_path, train_file, test_file, dev_file):\n",
    "    columns = {0 : 'text', 1 : 'ner'}\n",
    "    corpus = ColumnCorpus(input_path, columns, train_file=train_file, test_file=test_file, dev_file=dev_file)\n",
    "    corpus._train = filter_long(corpus.train)\n",
    "    corpus._dev = filter_long(corpus.dev)\n",
    "    corpus._test = filter_long(corpus.test)\n",
    "    embeddings = TransformerWordEmbeddings(BERT_MODEL_DIR, cache_dir=CACHE_DIR, allow_long_sentences=False, fine_tune=True, layers='-1')\n",
    "    tagger = SequenceTagger(hidden_size=HIDDEN_SIZE, embeddings=embeddings, tag_dictionary=corpus.make_label_dictionary(label_type='ner'), tag_type='ner', use_crf=True)\n",
    "    trainer = ModelTrainer(tagger, corpus)\n",
    "    trainer.train('finbert', learning_rate=0.1, mini_batch_size=BATCH_SIZE, max_epochs=MAX_EPOCHS, embeddings_storage_mode='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:17:06,229 Reading data from data\n",
      "2022-05-04 15:17:06,229 Train: data/data_train.txt\n",
      "2022-05-04 15:17:06,230 Dev: None\n",
      "2022-05-04 15:17:06,230 Test: data/data_test.txt\n",
      "2022-05-04 15:17:11,896 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1046it [00:00, 95009.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:17:11,910 Dictionary created for label 'ner' with 5 values: PERSON (seen 661 times), ORG (seen 230 times), LOC (seen 162 times), MISC (seen 7 times)\n",
      "2022-05-04 15:17:11,911 SequenceTagger predicts: Dictionary with 17 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-ORG, B-ORG, E-ORG, I-ORG, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:17:12,568 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,570 Model: \"SequenceTagger(\n",
      "  (embeddings): TransformerWordEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (rnn): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=256, out_features=19, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2022-05-04 15:17:12,572 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,572 Corpus: \"Corpus: 1046 train + 114 dev + 299 test sentences\"\n",
      "2022-05-04 15:17:12,573 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,573 Parameters:\n",
      "2022-05-04 15:17:12,574  - learning_rate: \"0.100000\"\n",
      "2022-05-04 15:17:12,574  - mini_batch_size: \"4\"\n",
      "2022-05-04 15:17:12,575  - patience: \"3\"\n",
      "2022-05-04 15:17:12,575  - anneal_factor: \"0.5\"\n",
      "2022-05-04 15:17:12,576  - max_epochs: \"10\"\n",
      "2022-05-04 15:17:12,576  - shuffle: \"True\"\n",
      "2022-05-04 15:17:12,577  - train_with_dev: \"False\"\n",
      "2022-05-04 15:17:12,577  - batch_growth_annealing: \"False\"\n",
      "2022-05-04 15:17:12,578 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,578 Model training base path: \"finbert\"\n",
      "2022-05-04 15:17:12,579 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,579 Device: cuda:0\n",
      "2022-05-04 15:17:12,580 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:12,581 Embeddings storage mode: gpu\n",
      "2022-05-04 15:17:12,581 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:14,894 epoch 1 - iter 26/262 - loss 0.55193510 - samples/sec: 45.01 - lr: 0.100000\n",
      "2022-05-04 15:17:17,242 epoch 1 - iter 52/262 - loss 0.42045223 - samples/sec: 44.33 - lr: 0.100000\n",
      "2022-05-04 15:17:19,468 epoch 1 - iter 78/262 - loss 0.44557031 - samples/sec: 46.76 - lr: 0.100000\n",
      "2022-05-04 15:17:21,963 epoch 1 - iter 104/262 - loss 0.38519592 - samples/sec: 41.72 - lr: 0.100000\n",
      "2022-05-04 15:17:24,028 epoch 1 - iter 130/262 - loss 0.35162032 - samples/sec: 50.40 - lr: 0.100000\n",
      "2022-05-04 15:17:25,887 epoch 1 - iter 156/262 - loss 0.33798324 - samples/sec: 56.01 - lr: 0.100000\n",
      "2022-05-04 15:17:29,016 epoch 1 - iter 182/262 - loss 0.33222757 - samples/sec: 33.26 - lr: 0.100000\n",
      "2022-05-04 15:17:31,683 epoch 1 - iter 208/262 - loss 0.30854727 - samples/sec: 39.03 - lr: 0.100000\n",
      "2022-05-04 15:17:34,840 epoch 1 - iter 234/262 - loss 0.30742587 - samples/sec: 32.96 - lr: 0.100000\n",
      "2022-05-04 15:17:37,155 epoch 1 - iter 260/262 - loss 0.28767082 - samples/sec: 44.96 - lr: 0.100000\n",
      "2022-05-04 15:17:37,247 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:37,248 EPOCH 1 done: loss 0.2891 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:17:38,748 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:17:38,754 DEV : loss 0.06763340532779694 - f1-score (micro avg)  0.7484\n",
      "2022-05-04 15:17:38,758 BAD EPOCHS (no improvement): 0\n",
      "2022-05-04 15:17:38,761 saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:17:40,505 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:17:43,374 epoch 2 - iter 26/262 - loss 0.19393792 - samples/sec: 36.28 - lr: 0.100000\n",
      "2022-05-04 15:17:45,941 epoch 2 - iter 52/262 - loss 0.20235445 - samples/sec: 40.55 - lr: 0.100000\n",
      "2022-05-04 15:17:48,613 epoch 2 - iter 78/262 - loss 0.22486070 - samples/sec: 38.94 - lr: 0.100000\n",
      "2022-05-04 15:17:50,985 epoch 2 - iter 104/262 - loss 0.22641256 - samples/sec: 43.89 - lr: 0.100000\n",
      "2022-05-04 15:17:53,429 epoch 2 - iter 130/262 - loss 0.22687826 - samples/sec: 42.57 - lr: 0.100000\n",
      "2022-05-04 15:17:55,808 epoch 2 - iter 156/262 - loss 0.23221175 - samples/sec: 43.76 - lr: 0.100000\n",
      "2022-05-04 15:17:58,383 epoch 2 - iter 182/262 - loss 0.24994298 - samples/sec: 40.42 - lr: 0.100000\n",
      "2022-05-04 15:18:00,774 epoch 2 - iter 208/262 - loss 0.25629811 - samples/sec: 43.52 - lr: 0.100000\n",
      "2022-05-04 15:18:03,231 epoch 2 - iter 234/262 - loss 0.26105162 - samples/sec: 42.36 - lr: 0.100000\n",
      "2022-05-04 15:18:05,440 epoch 2 - iter 260/262 - loss 0.27413867 - samples/sec: 47.12 - lr: 0.100000\n",
      "2022-05-04 15:18:05,565 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:18:05,566 EPOCH 2 done: loss 0.2758 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:18:06,918 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:18:06,923 DEV : loss 0.19801780581474304 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:18:06,927 BAD EPOCHS (no improvement): 1\n",
      "2022-05-04 15:18:06,930 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:18:09,391 epoch 3 - iter 26/262 - loss 0.32531911 - samples/sec: 42.30 - lr: 0.100000\n",
      "2022-05-04 15:18:11,741 epoch 3 - iter 52/262 - loss 0.36047539 - samples/sec: 44.29 - lr: 0.100000\n",
      "2022-05-04 15:18:14,526 epoch 3 - iter 78/262 - loss 0.34787363 - samples/sec: 37.37 - lr: 0.100000\n",
      "2022-05-04 15:18:17,147 epoch 3 - iter 104/262 - loss 0.33406861 - samples/sec: 39.70 - lr: 0.100000\n",
      "2022-05-04 15:18:19,696 epoch 3 - iter 130/262 - loss 0.31748376 - samples/sec: 40.83 - lr: 0.100000\n",
      "2022-05-04 15:18:22,131 epoch 3 - iter 156/262 - loss 0.29436651 - samples/sec: 42.74 - lr: 0.100000\n",
      "2022-05-04 15:18:24,544 epoch 3 - iter 182/262 - loss 0.28469263 - samples/sec: 43.13 - lr: 0.100000\n",
      "2022-05-04 15:18:26,846 epoch 3 - iter 208/262 - loss 0.28003047 - samples/sec: 45.21 - lr: 0.100000\n",
      "2022-05-04 15:18:29,181 epoch 3 - iter 234/262 - loss 0.27645516 - samples/sec: 44.58 - lr: 0.100000\n",
      "2022-05-04 15:18:31,669 epoch 3 - iter 260/262 - loss 0.26877406 - samples/sec: 41.84 - lr: 0.100000\n",
      "2022-05-04 15:18:31,810 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:18:31,811 EPOCH 3 done: loss 0.2680 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:18:33,169 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:18:33,175 DEV : loss 0.1679811179637909 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:18:33,179 BAD EPOCHS (no improvement): 2\n",
      "2022-05-04 15:18:33,181 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:18:35,622 epoch 4 - iter 26/262 - loss 0.29412592 - samples/sec: 42.67 - lr: 0.100000\n",
      "2022-05-04 15:18:38,270 epoch 4 - iter 52/262 - loss 0.23144518 - samples/sec: 39.29 - lr: 0.100000\n",
      "2022-05-04 15:18:40,586 epoch 4 - iter 78/262 - loss 0.24261276 - samples/sec: 44.94 - lr: 0.100000\n",
      "2022-05-04 15:18:43,079 epoch 4 - iter 104/262 - loss 0.23874697 - samples/sec: 41.75 - lr: 0.100000\n",
      "2022-05-04 15:18:45,967 epoch 4 - iter 130/262 - loss 0.23686611 - samples/sec: 36.03 - lr: 0.100000\n",
      "2022-05-04 15:18:48,427 epoch 4 - iter 156/262 - loss 0.23985840 - samples/sec: 42.30 - lr: 0.100000\n",
      "2022-05-04 15:18:50,911 epoch 4 - iter 182/262 - loss 0.24235813 - samples/sec: 41.90 - lr: 0.100000\n",
      "2022-05-04 15:18:53,278 epoch 4 - iter 208/262 - loss 0.24547239 - samples/sec: 43.97 - lr: 0.100000\n",
      "2022-05-04 15:18:55,530 epoch 4 - iter 234/262 - loss 0.24109890 - samples/sec: 46.23 - lr: 0.100000\n",
      "2022-05-04 15:18:58,220 epoch 4 - iter 260/262 - loss 0.24817566 - samples/sec: 38.69 - lr: 0.100000\n",
      "2022-05-04 15:18:58,385 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:18:58,386 EPOCH 4 done: loss 0.2471 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:18:59,755 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:18:59,760 DEV : loss 0.1901572346687317 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:18:59,764 BAD EPOCHS (no improvement): 3\n",
      "2022-05-04 15:18:59,768 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:19:02,523 epoch 5 - iter 26/262 - loss 0.16439327 - samples/sec: 37.77 - lr: 0.100000\n",
      "2022-05-04 15:19:04,686 epoch 5 - iter 52/262 - loss 0.20681163 - samples/sec: 48.13 - lr: 0.100000\n",
      "2022-05-04 15:19:07,519 epoch 5 - iter 78/262 - loss 0.19798867 - samples/sec: 36.74 - lr: 0.100000\n",
      "2022-05-04 15:19:09,964 epoch 5 - iter 104/262 - loss 0.21422582 - samples/sec: 42.55 - lr: 0.100000\n",
      "2022-05-04 15:19:12,296 epoch 5 - iter 130/262 - loss 0.23460667 - samples/sec: 44.65 - lr: 0.100000\n",
      "2022-05-04 15:19:14,790 epoch 5 - iter 156/262 - loss 0.23826677 - samples/sec: 41.73 - lr: 0.100000\n",
      "2022-05-04 15:19:17,551 epoch 5 - iter 182/262 - loss 0.22842899 - samples/sec: 37.70 - lr: 0.100000\n",
      "2022-05-04 15:19:20,111 epoch 5 - iter 208/262 - loss 0.23721945 - samples/sec: 40.65 - lr: 0.100000\n",
      "2022-05-04 15:19:22,473 epoch 5 - iter 234/262 - loss 0.24012122 - samples/sec: 44.05 - lr: 0.100000\n",
      "2022-05-04 15:19:24,786 epoch 5 - iter 260/262 - loss 0.24124429 - samples/sec: 45.00 - lr: 0.100000\n",
      "2022-05-04 15:19:24,994 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:19:24,995 EPOCH 5 done: loss 0.2410 - lr 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:19:26,380 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:19:26,385 DEV : loss 0.15713681280612946 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:19:26,389 Epoch     5: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2022-05-04 15:19:26,391 BAD EPOCHS (no improvement): 4\n",
      "2022-05-04 15:19:26,392 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:19:28,825 epoch 6 - iter 26/262 - loss 0.24538227 - samples/sec: 42.80 - lr: 0.050000\n",
      "2022-05-04 15:19:31,643 epoch 6 - iter 52/262 - loss 0.25067848 - samples/sec: 36.93 - lr: 0.050000\n",
      "2022-05-04 15:19:34,117 epoch 6 - iter 78/262 - loss 0.21943403 - samples/sec: 42.06 - lr: 0.050000\n",
      "2022-05-04 15:19:36,771 epoch 6 - iter 104/262 - loss 0.21974063 - samples/sec: 39.21 - lr: 0.050000\n",
      "2022-05-04 15:19:38,957 epoch 6 - iter 130/262 - loss 0.21515353 - samples/sec: 47.63 - lr: 0.050000\n",
      "2022-05-04 15:19:41,470 epoch 6 - iter 156/262 - loss 0.20713159 - samples/sec: 41.43 - lr: 0.050000\n",
      "2022-05-04 15:19:43,763 epoch 6 - iter 182/262 - loss 0.21636648 - samples/sec: 45.39 - lr: 0.050000\n",
      "2022-05-04 15:19:46,326 epoch 6 - iter 208/262 - loss 0.21682485 - samples/sec: 40.61 - lr: 0.050000\n",
      "2022-05-04 15:19:48,716 epoch 6 - iter 234/262 - loss 0.21491867 - samples/sec: 43.55 - lr: 0.050000\n",
      "2022-05-04 15:19:51,210 epoch 6 - iter 260/262 - loss 0.21310584 - samples/sec: 41.73 - lr: 0.050000\n",
      "2022-05-04 15:19:51,353 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:19:51,354 EPOCH 6 done: loss 0.2129 - lr 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:19:52,721 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:19:52,726 DEV : loss 0.15270304679870605 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:19:52,730 BAD EPOCHS (no improvement): 1\n",
      "2022-05-04 15:19:52,733 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:19:54,938 epoch 7 - iter 26/262 - loss 0.25855455 - samples/sec: 47.22 - lr: 0.050000\n",
      "2022-05-04 15:19:57,587 epoch 7 - iter 52/262 - loss 0.23541923 - samples/sec: 39.28 - lr: 0.050000\n",
      "2022-05-04 15:20:00,020 epoch 7 - iter 78/262 - loss 0.22740225 - samples/sec: 42.78 - lr: 0.050000\n",
      "2022-05-04 15:20:02,608 epoch 7 - iter 104/262 - loss 0.22660614 - samples/sec: 40.22 - lr: 0.050000\n",
      "2022-05-04 15:20:05,076 epoch 7 - iter 130/262 - loss 0.21518701 - samples/sec: 42.18 - lr: 0.050000\n",
      "2022-05-04 15:20:07,762 epoch 7 - iter 156/262 - loss 0.21259904 - samples/sec: 38.74 - lr: 0.050000\n",
      "2022-05-04 15:20:10,236 epoch 7 - iter 182/262 - loss 0.20854599 - samples/sec: 42.07 - lr: 0.050000\n",
      "2022-05-04 15:20:12,476 epoch 7 - iter 208/262 - loss 0.21941108 - samples/sec: 46.49 - lr: 0.050000\n",
      "2022-05-04 15:20:14,797 epoch 7 - iter 234/262 - loss 0.21313670 - samples/sec: 44.85 - lr: 0.050000\n",
      "2022-05-04 15:20:17,445 epoch 7 - iter 260/262 - loss 0.21412424 - samples/sec: 39.30 - lr: 0.050000\n",
      "2022-05-04 15:20:17,630 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:20:17,631 EPOCH 7 done: loss 0.2140 - lr 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:20:19,018 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:20:19,023 DEV : loss 0.14573818445205688 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:20:19,028 BAD EPOCHS (no improvement): 2\n",
      "2022-05-04 15:20:19,030 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:20:21,904 epoch 8 - iter 26/262 - loss 0.21247075 - samples/sec: 36.22 - lr: 0.050000\n",
      "2022-05-04 15:20:24,412 epoch 8 - iter 52/262 - loss 0.21374248 - samples/sec: 41.50 - lr: 0.050000\n",
      "2022-05-04 15:20:27,027 epoch 8 - iter 78/262 - loss 0.19672160 - samples/sec: 39.80 - lr: 0.050000\n",
      "2022-05-04 15:20:29,525 epoch 8 - iter 104/262 - loss 0.19664724 - samples/sec: 41.66 - lr: 0.050000\n",
      "2022-05-04 15:20:31,877 epoch 8 - iter 130/262 - loss 0.20012333 - samples/sec: 44.26 - lr: 0.050000\n",
      "2022-05-04 15:20:34,318 epoch 8 - iter 156/262 - loss 0.20301133 - samples/sec: 42.64 - lr: 0.050000\n",
      "2022-05-04 15:20:36,928 epoch 8 - iter 182/262 - loss 0.20675537 - samples/sec: 39.87 - lr: 0.050000\n",
      "2022-05-04 15:20:39,250 epoch 8 - iter 208/262 - loss 0.20905129 - samples/sec: 44.82 - lr: 0.050000\n",
      "2022-05-04 15:20:41,628 epoch 8 - iter 234/262 - loss 0.20382814 - samples/sec: 43.77 - lr: 0.050000\n",
      "2022-05-04 15:20:44,109 epoch 8 - iter 260/262 - loss 0.20641349 - samples/sec: 41.95 - lr: 0.050000\n",
      "2022-05-04 15:20:44,385 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:20:44,386 EPOCH 8 done: loss 0.2055 - lr 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:20:45,768 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:20:45,773 DEV : loss 0.1505756378173828 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:20:45,778 BAD EPOCHS (no improvement): 3\n",
      "2022-05-04 15:20:45,781 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:20:48,267 epoch 9 - iter 26/262 - loss 0.16672544 - samples/sec: 41.87 - lr: 0.050000\n",
      "2022-05-04 15:20:50,709 epoch 9 - iter 52/262 - loss 0.22085376 - samples/sec: 42.62 - lr: 0.050000\n",
      "2022-05-04 15:20:53,331 epoch 9 - iter 78/262 - loss 0.22643759 - samples/sec: 39.70 - lr: 0.050000\n",
      "2022-05-04 15:20:55,911 epoch 9 - iter 104/262 - loss 0.21694350 - samples/sec: 40.34 - lr: 0.050000\n",
      "2022-05-04 15:20:58,560 epoch 9 - iter 130/262 - loss 0.20652611 - samples/sec: 39.28 - lr: 0.050000\n",
      "2022-05-04 15:21:01,139 epoch 9 - iter 156/262 - loss 0.19397056 - samples/sec: 40.36 - lr: 0.050000\n",
      "2022-05-04 15:21:03,581 epoch 9 - iter 182/262 - loss 0.20702496 - samples/sec: 42.61 - lr: 0.050000\n",
      "2022-05-04 15:21:06,327 epoch 9 - iter 208/262 - loss 0.20730400 - samples/sec: 37.90 - lr: 0.050000\n",
      "2022-05-04 15:21:08,839 epoch 9 - iter 234/262 - loss 0.20487681 - samples/sec: 41.44 - lr: 0.050000\n",
      "2022-05-04 15:21:11,139 epoch 9 - iter 260/262 - loss 0.20530463 - samples/sec: 45.26 - lr: 0.050000\n",
      "2022-05-04 15:21:11,276 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:21:11,277 EPOCH 9 done: loss 0.2054 - lr 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:21:12,653 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:21:12,658 DEV : loss 0.1411881297826767 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:21:12,663 Epoch     9: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2022-05-04 15:21:12,665 BAD EPOCHS (no improvement): 4\n",
      "2022-05-04 15:21:12,667 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:21:15,481 epoch 10 - iter 26/262 - loss 0.17958983 - samples/sec: 36.99 - lr: 0.025000\n",
      "2022-05-04 15:21:18,021 epoch 10 - iter 52/262 - loss 0.18921819 - samples/sec: 40.97 - lr: 0.025000\n",
      "2022-05-04 15:21:20,254 epoch 10 - iter 78/262 - loss 0.18866043 - samples/sec: 46.62 - lr: 0.025000\n",
      "2022-05-04 15:21:23,024 epoch 10 - iter 104/262 - loss 0.18026621 - samples/sec: 37.57 - lr: 0.025000\n",
      "2022-05-04 15:21:25,618 epoch 10 - iter 130/262 - loss 0.17473228 - samples/sec: 40.11 - lr: 0.025000\n",
      "2022-05-04 15:21:27,719 epoch 10 - iter 156/262 - loss 0.17772628 - samples/sec: 49.56 - lr: 0.025000\n",
      "2022-05-04 15:21:30,377 epoch 10 - iter 182/262 - loss 0.18227537 - samples/sec: 39.15 - lr: 0.025000\n",
      "2022-05-04 15:21:32,703 epoch 10 - iter 208/262 - loss 0.18994752 - samples/sec: 44.74 - lr: 0.025000\n",
      "2022-05-04 15:21:35,123 epoch 10 - iter 234/262 - loss 0.19844643 - samples/sec: 43.01 - lr: 0.025000\n",
      "2022-05-04 15:21:37,796 epoch 10 - iter 260/262 - loss 0.19398956 - samples/sec: 38.94 - lr: 0.025000\n",
      "2022-05-04 15:21:37,934 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:21:37,935 EPOCH 10 done: loss 0.1939 - lr 0.025000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:21:39,479 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:21:39,484 DEV : loss 0.14075566828250885 - f1-score (micro avg)  0.0\n",
      "2022-05-04 15:21:39,489 BAD EPOCHS (no improvement): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:21:41,262 ----------------------------------------------------------------------------------------------------\n",
      "2022-05-04 15:21:41,265 loading file finbert/best-model.pt\n",
      "2022-05-04 15:23:10,072 SequenceTagger predicts: Dictionary with 19 tags: O, S-PERSON, B-PERSON, E-PERSON, I-PERSON, S-ORG, B-ORG, E-ORG, I-ORG, S-LOC, B-LOC, E-LOC, I-LOC, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:04<00:00, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:23:16,177 Evaluating as a multi-label problem: False\n",
      "2022-05-04 15:23:16,184 0.6\t0.594\t0.597\t0.455\n",
      "2022-05-04 15:23:16,185 \n",
      "Results:\n",
      "- F-score (micro) 0.597\n",
      "- F-score (macro) 0.1867\n",
      "- Accuracy 0.455\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      PERSON     0.6390    0.8985    0.7468       197\n",
      "         ORG     0.0000    0.0000    0.0000        56\n",
      "         LOC     0.0000    0.0000    0.0000        39\n",
      "        MISC     0.0000    0.0000    0.0000         6\n",
      "\n",
      "   micro avg     0.6000    0.5940    0.5970       298\n",
      "   macro avg     0.1597    0.2246    0.1867       298\n",
      "weighted avg     0.4224    0.5940    0.4937       298\n",
      "\n",
      "2022-05-04 15:23:16,186 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tagger('data', 'data_train.txt', 'data_test.txt', None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98601fdff9a4c16ad820886e04bd436b4228b3a5cc1d045d72d4526e75f669cf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
